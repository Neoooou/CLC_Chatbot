Best: 0.8122362904407807 using {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
grid scores on development set:
0.788 (+/-0.051) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.362 (+/-0.013) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.809 (+/-0.039) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.789 (+/-0.044) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.361 (+/-0.019) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.802 (+/-0.048) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.783 (+/-0.044) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.367 (+/-0.018) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.806 (+/-0.047) for {'activation_': 'tanh', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.781 (+/-0.049) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.291 (+/-0.108) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.799 (+/-0.024) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.788 (+/-0.054) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.300 (+/-0.039) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.812 (+/-0.027) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.802 (+/-0.058) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.270 (+/-0.070) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.805 (+/-0.044) for {'activation_': 'tanh', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.695 (+/-0.053) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.150 (+/-0.011) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.780 (+/-0.037) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.657 (+/-0.079) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.145 (+/-0.025) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.767 (+/-0.018) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.614 (+/-0.039) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.149 (+/-0.034) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.739 (+/-0.036) for {'activation_': 'sigmoid', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.538 (+/-0.067) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.141 (+/-0.023) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.728 (+/-0.010) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.479 (+/-0.255) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.152 (+/-0.036) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.660 (+/-0.098) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.484 (+/-0.154) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.150 (+/-0.011) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.531 (+/-0.112) for {'activation_': 'sigmoid', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.799 (+/-0.040) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.248 (+/-0.127) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.806 (+/-0.042) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.793 (+/-0.052) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.255 (+/-0.090) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.806 (+/-0.031) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.803 (+/-0.059) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.233 (+/-0.133) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.806 (+/-0.031) for {'activation_': 'relu', 'batch_size': 32, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.803 (+/-0.040) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.196 (+/-0.080) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.810 (+/-0.037) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.3, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.792 (+/-0.044) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.167 (+/-0.052) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.812 (+/-0.026) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.4, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
0.795 (+/-0.050) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'rmsprop', 'vocab_size': 2420}
0.200 (+/-0.052) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'sgd', 'vocab_size': 2420}
0.800 (+/-0.034) for {'activation_': 'relu', 'batch_size': 64, 'dropout_rate': 0.5, 'epochs': 32, 'optimizer': 'adam', 'vocab_size': 2420}
Detailed classification report:

The model is trained on the full development set.
The scores are computed on the full evaluation set.

             precision    recall  f1-score   support

          0       0.73      0.86      0.79        43
          1       0.67      0.71      0.69        41
          2       0.78      0.93      0.85        27
          3       0.76      0.70      0.73        23
          4       0.94      0.84      0.89        19
          5       0.67      0.57      0.62        14
          6       0.86      1.00      0.92        12
          7       0.92      0.92      0.92        13
          8       0.80      0.60      0.69        20
          9       0.58      0.44      0.50        25

avg / total       0.75      0.75      0.74       237
